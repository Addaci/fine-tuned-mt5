# Install necessary libraries
!pip install --upgrade transformers datasets

# Mount Google Drive to Colab
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer
from datasets import Dataset, DatasetDict

# Define file paths
csv_path = "/content/drive/MyDrive/Colab Notebooks/HCA_1358_Paired_Line_Text_Ver.1.2_15102024.csv"

# Load the CSV data into a Pandas DataFrame
df = pd.read_csv(csv_path)  # Pandas automatically detects the header

# Get the raw_htr and groundtruth lists from the DataFrame
raw_htr_texts = df['Raw-HTR Text'].tolist()  # Accessing by column name
groundtruth_texts = df['Hand-corrected Groundtruth'].tolist()

# Initialize the T5 tokenizer
tokenizer = T5Tokenizer.from_pretrained("google/mt5-small")

# Tokenize the data
def preprocess_function(examples):
    inputs = [doc for doc in examples['Raw-HTR Text']]  # Using column name
    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding="max_length")

    with tokenizer.as_target_tokenizer():
        # Corrected line: Ensuring the string is properly terminated
        labels = tokenizer(examples['Hand-corrected Groundtruth'], max_length=128, truncation=True, padding="max_length")

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

# Create a Hugging Face Dataset
data = Dataset.from_dict({"Raw-HTR Text": raw_htr_texts, "Hand-corrected Groundtruth": groundtruth_texts})  # Using column names
tokenized_data = data.map(preprocess_function, batched=True)

# Split the data into training and validation sets
train_testvalid = tokenized_data.train_test_split(test_size=0.2)
test_valid = train_testvalid['test'].train_test_split(test_size=0.5)
dataset = DatasetDict({
    'train': train_testvalid['train'],
    'test': test_valid['test'],

    'validation': test_valid['train']})


# Initialize the mT5-small model
model = T5ForConditionalGeneration.from_pretrained("google/mt5-small")

# Define training arguments
training_args = TrainingArguments(
    output_dir="./results_experiment_2",
    per_device_train_batch_size=8,  # Adjust based on your GPU memory
    per_device_eval_batch_size=8,
    # predict_with_generate=True,  # Removed in previous step
    learning_rate=2e-5,  # You can experiment with different learning rates
    num_train_epochs=5,  # Start with a few epochs and adjust
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    # Early stopping parameters:
    metric_for_best_model="eval_loss",
    greater_is_better=False,
    # early_stopping_patience=3, # Removed for now
    logging_strategy="epoch",  # Log training loss at each epoch
)

# Define compute_metrics function
import nltk  # Make sure nltk is installed
from datasets import load_metric
nltk.download('punkt')  # Download necessary data for nltk

bleu_metric = load_metric("bleu")
rouge_metric = load_metric("rouge") 

def compute_metrics(pred):
    labels_ids = pred.label_ids
    pred_ids = pred.predictions

    # Decode the predictions and labels
    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    labels_ids[labels_ids == -100] = tokenizer.pad_token_id
    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)  


    # Calculate BLEU 
    bleu_output = bleu_metric.compute(predictions=pred_str, references=[[r] for r in label_str])

    # Calculate ROUGE
    rouge_output = rouge_metric.compute(predictions=pred_str, references=label_str, rouge_types=["rouge2"])["rouge2"].mid

    return {"bleu": bleu_output["bleu"], "rouge2": round(rouge_output.fmeasure, 4)}

# Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"]
    compute_metrics=compute_metrics, 
)

# Fine-tune the model
trainer.train()


# Evaluate the model
eval_results = trainer.evaluate()
print(f"Evaluation results: {eval_results}")
